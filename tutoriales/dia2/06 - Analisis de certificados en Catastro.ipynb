{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de certificados en Catastro\n",
    "\n",
    "**Autor:** Roberto Muñoz <br />\n",
    "**E-mail:** <rmunoz@metricarts.com> <br />\n",
    "**Github:** <https://github.com/rpmunoz> <br />\n",
    "\n",
    "La división de gobierno digital necesita crear un método que identifique y clasifique de manera automática los trámites que están disponibles en la página web www.chileatiende.cl\n",
    "\n",
    "En este notebook veremos como usar pandas para cargas archivos excel e identificar los trámites que son del tipo certificados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargamos en memoria el archivo de Catastro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catastro_file=\"data/Catastro 23082018 V4.xlsx\"\n",
    "catastro_df=pd.read_excel(catastro_file)\n",
    "catastro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catastro_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(catastro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(catastro_df['ID trámite'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(catastro_df['Nombre del trámite'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', 300):\n",
    "    print(catastro_df.loc[catastro_df['Nombre del trámite'].str.contains('nacimiento'), ['ID trámite','Nombre del trámite']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extraemos las columnas de interes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns=['ID trámite','Nombre del trámite','Requisitos']\n",
    "\n",
    "data_df = catastro_df[columns].copy()\n",
    "data_df.rename(index=int, columns={'ID trámite': 'id_tramite', 'Nombre del trámite': 'nombre_tramite', 'Requisitos': 'requisitos'}, inplace=True)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos el campo ID trámite a un tipo de datos string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df['id_tramite'] = data_df['id_tramite'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df['LEN_id_tramite'] = data_df['id_tramite'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenamos por el largo del campo id_tramite para identificar posibles errores en el tipeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sort_values('LEN_id_tramite').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indentificamos los registros con ID trámite NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[data_df['id_tramite'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indentificamos los registros con ID trámite = NUEVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[data_df['id_tramite'].str.contains('NUEVO')].sort_values('id_tramite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copiamos el index en un campo llamado row_excel y sumamos el valor 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limpiamos y parseamos el campo requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def standardize_string(row):\n",
    "    result = row.lower()\n",
    "    result = unicodedata.normalize('NFD', result)\n",
    "    result = result.encode('ascii', 'ignore')\n",
    "    result = result.decode(\"utf-8\")\n",
    "    return result\n",
    "\n",
    "def parse_string(row):\n",
    "    #result = re.split('-|\\n', row)\n",
    "    #result = list(map(lambda x: re.sub('\\n$', '', x), result))\n",
    "    result = re.split('-', row)\n",
    "    result = list(map(lambda x: x.replace('\\n', ' '), result))\n",
    "    result = list(map(lambda x: re.sub(' +', ' ', x), result))\n",
    "    result = list(map(str.strip, result))\n",
    "    result = list(filter(None, result))\n",
    "    return result\n",
    "\n",
    "def parse_string_new_line(row):\n",
    "    result = re.split('\\n', row)\n",
    "    result = list(map(str.strip, result))\n",
    "    result = list(filter(None, result))\n",
    "    return result\n",
    "\n",
    "def remove_numbering(row):\n",
    "    result = list(map(lambda x: re.sub('^[0-9]+\\.', '', x), row))\n",
    "    result = list(map(str.strip, result))\n",
    "    return result\n",
    "    \n",
    "def remove_stopwords(row):\n",
    "    stop_spanish = stopwords.words('spanish')\n",
    "    \n",
    "    result = ' '.join([word for word in row])\n",
    "    result = ' '.join([word for word in result.split() if word not in stop_spanish])\n",
    "    return result\n",
    "\n",
    "def get_max_length(row):\n",
    "    result=[]\n",
    "    for word in row:\n",
    "        result.append(len(word))\n",
    "    result = max(result)\n",
    "    return result\n",
    "\n",
    "def get_number_new_line(row):\n",
    "    result=0\n",
    "    for word in row:\n",
    "        result += len(re.findall(\"\\n\", word))\n",
    "    return result\n",
    "\n",
    "def get_hyphens_numbers(row):\n",
    "    result=re.findall(\"\\w+.{,2}(?:[0-9]+|[a-zA-Z]+)-(?:[0-9]+).{,2}\\w+\", row)\n",
    "    return result\n",
    "\n",
    "def get_hyphens(row):\n",
    "    result=re.findall(\"\\w+.{,2}\\w+-\\w+.{,2}\\w+\", row)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificamos las palabras que estan unidas por guiones y reemplazamos - por _ para estos pocos casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df['requisitos_clean'] = data_df['requisitos'].apply(standardize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#temp_df=data_df['requisitos_clean'].apply(get_hyphens)\n",
    "#temp_df=temp_df[temp_df.str.len() > 0]\n",
    "#for idx, row in temp_df.iteritems():\n",
    "#    print(idx, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyphens_list1=['te-4','formulario sl-1','datum wgs-84','900.183-2','v-5','901265-6','fpi-50',\n",
    "               'o-71/026','o-73/002','certificado f-30','mp3-256 kbps','formulario 30-1','gr -g-03','weg-84',\n",
    "               'w3-article-4833', 'articles-4833_recurso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyphens_list2=['e-declarador','chile-espana','ipso-jure','visa-de-residencia',\n",
    "               'solicitud-reconcideracio','81n-visa','permanencia-definitiva','directores-accionistas',\n",
    "               'teorico-practico','on-line','re-exportacion','formulario-tipo','sub-rol','compra-venta',\n",
    "               'empresa-individual','ex-cora','poblacion-objetivo','carta-compromiso','ips-chileatiende',\n",
    "               'im-ponentes','anos-calendario','teorica-metodologica','tele-vigilancia','mai-ges','in-situ',\n",
    "               'y de-los','urbano-arquitectonico','documentacion- del ano en curso-que','blu-ray','bio-bibliografica',\n",
    "               'post-doctorados','cd-rom','ingreso-sai-v2','declara-cion','en-tidad','anexo n 8-a','imp-mp3',\n",
    "               're-circulacion','inn-sernapesca','co-responsables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyphens_list = hyphens_list1 + hyphens_list2\n",
    "hyphens_dict = {x: x.replace('-', '_') for x in hyphens_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, val in hyphens_dict.items():\n",
    "    data_df['requisitos_clean'] = data_df['requisitos_clean'].str.replace(key, val, regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacemos un parsing del campo requisitos_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df['LEN_requisitos_clean'] = data_df['requisitos_clean'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df['N_NEW_LINE_requisitos_clean'] = data_df['requisitos_clean'].apply(get_number_new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df['requisitos_parse'] = data_df['requisitos_clean'].apply(parse_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df['requisitos_parse'] = data_df['requisitos_parse'].apply(remove_numbering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df['MAX_LEN_requisitos_parse'] = data_df['requisitos_parse'].apply(get_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df['N_requisitos_parse'] = data_df['requisitos_parse'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df['id_tramite']=='SINID778']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscamos registros que contengan un gran numero de saltos de linea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = data_df.sort_values('N_requisitos_parse', ascending=True)\n",
    "temp_df['ratio_N_NEW_LINE'] = temp_df['N_NEW_LINE_requisitos_clean']/temp_df['N_requisitos_parse']\n",
    "\n",
    "columns=['id_tramite','MAX_LEN_requisitos_parse','N_requisitos_parse','N_NEW_LINE_requisitos_clean','ratio_N_NEW_LINE']\n",
    "temp_df = temp_df[temp_df['N_requisitos_parse']<=10][columns]\n",
    "temp_df = temp_df.sort_values('ratio_N_NEW_LINE', ascending=False).head(30)\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[2896,'requisitos_parse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "\n",
    "output_file='results/catastro_tramites - revisar_saltos_linea_requisitos.xlsx'\n",
    "\n",
    "writer = pd.ExcelWriter(output_file, engine='xlsxwriter')\n",
    "temp_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "worksheet.set_column('A:E', 20)\n",
    "\n",
    "end_row = len(temp_df.index)\n",
    "end_column = len(temp_df.columns)-1\n",
    "header = [{'header': word} for word in temp_df.columns.tolist()]\n",
    "\n",
    "worksheet.add_table(0, 0, end_row, end_column, {'header_row': True, 'columns': header})\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenamos los registros por el largo del campo requisitos_clean - LEN_requisitos_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sort_values('LEN_requisitos_clean', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sort_values('LEN_requisitos_clean', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos el registro 4173, el cual tiene un largo de 10741 caracteres el campo requisitos y solo fue parseado en 17 elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.loc[4173, 'requisitos_parse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenamos los registros por el numero de elementos del campo requisitos_parse - N_requisitos_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.sort_values('N_requisitos_parse', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.sort_values('N_requisitos_parse', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df.sort_values('N_requisitos_parse', ascending=False).head(100).to_excel('results/catastro_tramites - N_requisitos_parse.xlsx', \n",
    "            startcol=0,\n",
    "            startrow=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos el registro con indice 2893, que contiene 48 parrafos y el parrafo mas largo tiene 1427 caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.loc[2893, 'requisitos_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[2893, 'requisitos_parse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenamos los registros por el maximo largo de los elementos del campo requisitos_parse - MAX_LEN_requisitos_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.sort_values('MAX_LEN_requisitos_parse', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.sort_values('MAX_LEN_requisitos_parse', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df.sort_values('MAX_LEN_requisitos_parse', ascending=False).head(100).to_excel('results/catastro_tramites - MAX_LEN_requisitos_parse.xlsx', \n",
    "            startcol=0, \n",
    "            startrow=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Expandimos el campo requisitos_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "requisitos_df = (pd.melt(data_df['requisitos_parse'].apply(pd.Series).reset_index(), \n",
    "             id_vars='index',\n",
    "             value_name='requisitos_expand').rename_axis('idx')\n",
    "                 .drop('variable', axis=1)\n",
    "                 .dropna()\n",
    "                 .sort_values(['index','idx'])\n",
    "                 .set_index('index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requisitos_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_expand_df = data_df[['id_tramite','nombre_tramite','N_requisitos_parse']].join(requisitos_df, how='outer')\n",
    "data_expand_df = data_expand_df[['id_tramite','nombre_tramite','requisitos_expand','N_requisitos_parse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_expand_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_expand_df.to_excel('results/catastro_tramites - requisitos_expand.xlsx', \n",
    "            startcol=0, \n",
    "            startrow=0, \n",
    "            index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assert false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Creamos columnas para contar numero de caracteres y medir complejidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = data_expand_df['requisitos_expand'].apply(len)\n",
    "col.name = 'LEN_requisitos_str'\n",
    "data_expand_df.insert(data_expand_df.columns.get_loc('N_requisitos_parse') + 1, col.name, col)\n",
    "data_expand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = data_expand_df.groupby('id_tramite')\n",
    "len(group_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexity(row):\n",
    "    result = max(row['N_requisitos_parse']) * max(row['LEN_requisitos_str'])\n",
    "    return result\n",
    "\n",
    "complex_s = group_df.apply(complexity)\n",
    "#group_s.rename('complexity')\n",
    "\n",
    "complex_df = pd.DataFrame(complex_s, columns=['complexity']).reset_index()\n",
    "data_complexity_df = data_expand_df.merge(complex_df, on='id_tramite', how='outer')\n",
    "data_complexity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que calcularemos el logaritmo de be_complexity, convertimos todos los valores 0 a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_complexity_df.loc[data_complexity_df['complexity']==0,'complexity']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos algunos graficos para entender el comportamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df=data_complexity_df.groupby('id_tramite').max()\n",
    "group_df.sort_values('complexity', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df['complexity'].plot(kind='hist', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_val=max(np.log(group_df['complexity']))\n",
    "data_complexity_df['complexity_percentage'] = np.round(100*np.log(data_complexity_df['complexity'])/max_val,1)\n",
    "\n",
    "group_df=data_complexity_df.groupby('id_tramite').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.sort_values('complexity_percentage', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file='results/catastro_requisitos_complexity.xlsx'\n",
    "data_df = data_complexity_df.rename_axis('idx').sort_values(['complexity_percentage','idx'], ascending=[False,True])\n",
    "\n",
    "writer = pd.ExcelWriter(output_file, engine='xlsxwriter')\n",
    "data_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "format1 = workbook.add_format({'text_wrap': True})\n",
    "\n",
    "worksheet.set_column('A:A', 10)\n",
    "worksheet.set_column('B:C', 50, format1)\n",
    "worksheet.set_column('D:G', 20)\n",
    "\n",
    "end_row = len(data_df.index)\n",
    "end_column = len(data_df.columns)-1\n",
    "header = [{'header': word} for word in data_df.columns.tolist()]\n",
    "\n",
    "worksheet.add_table(0, 0, end_row, end_column, {'header_row': True, 'columns': header})\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assert false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Cargamos en memoria el listado de certificados identificados por la Segpres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segpres_certificados_file='data/Listado certificados - compartido a Metricarts.xlsx'\n",
    "segpres_certificados_sheetname='Listado CERTIFICADOS'\n",
    "segpres_certificados_df=pd.read_excel(segpres_certificados_file, sheet_name=segpres_certificados_sheetname)\n",
    "segpres_certificados_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segpres_certificados_df['nombre_certificado'] = segpres_certificados_df['Nombre del trámite'].apply(standardize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segpres_certificados_df.sort_values('nombre_certificado', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segpres_certificados_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinamos el numero de veces que se repiten los nombres de los certificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=segpres_certificados_df.groupby('nombre_certificado').size().reset_index(name='count')\n",
    "temp_df.sort_values('count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segpres_certificados_list = segpres_certificados_df['nombre_certificado'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segpres_certificados_dict = { name : [name] for name in segpres_certificados_list }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j = json.dumps(segpres_certificados_dict, indent=2)\n",
    "f = open('results/certificados_segpres.json', 'w')\n",
    "print(j, file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open(\"results/certificados_segpres.json\") as test:\n",
    "#    data = test.read()\n",
    "#    test_dict = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_dict[\"certificado anual de estudios\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(segpres_certificados_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segpres_certificados_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Análisis del campo requisitos_expand y creación de catastro_tramites - certificados\n",
    "\n",
    "Abrir terminal e instalar los siguientes paquetes\n",
    "\n",
    "`pip install fuzzywuzzy`\n",
    "\n",
    "`pip install python-Levenshtein`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso que queramos volver a cargar en memoria el modulo fuzz\n",
    "\n",
    "#import importlib\n",
    "#importlib.reload(fuzz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos solamente los registros que contienen la palabra certificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_expand_certificados_df = data_expand_df[data_expand_df['requisitos_expand'].str.contains(\"certificado\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_expand_certificados_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_expand_certificados_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_group = data_expand_certificados_df.groupby('id_tramite')\n",
    "len(temp_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de DataFrame usando lista de certificados de Gobierno Digital e identificados por Metric. Los certificados fueron contetanados en un solo string y registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_expand_certificados_group = data_expand_certificados_df.groupby('id_tramite')\n",
    "n_group = len(data_expand_certificados_group)\n",
    "\n",
    "data_tramites_certificados_list=[]\n",
    "for i, (name, group) in enumerate(data_expand_certificados_group):\n",
    "    requisitos_expand_list = list(group['requisitos_expand'])\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"Processing {} of {} - ID tramite: {}\".format(i, n_group, name))\n",
    "    \n",
    "    certificados_match_segpres = []\n",
    "    for requisito in requisitos_expand_list:\n",
    "        #print(requisito)\n",
    "        fuzz_match = process.extract(requisito, segpres_certificados_list, limit=2, scorer=fuzz.partial_ratio)\n",
    "        #print(fuzz_match)\n",
    "        for word in fuzz_match:\n",
    "            if word[1]>90:\n",
    "                certificados_match_segpres.append(word[0])\n",
    "    certificados_match_segpres = list(set(certificados_match_segpres))\n",
    "    \n",
    "    #print('requisitos_expand_list: ', requisitos_expand_list)\n",
    "    certificados_match_metric = []\n",
    "    for requisito in requisitos_expand_list:\n",
    "        #re_match = re.search('certificado\\S?\\s+\\w+\\s+\\w+', requisito)\n",
    "        re_match = re.findall('certificado.*?(?=certificado|$)', requisito)\n",
    "        for word in re_match:\n",
    "            # We match a phrase starting with the word certificado and add a maximum of 8 words\n",
    "            re_search=re.search('certificado(s)?(?:\\W+\\w+){,8}', word)\n",
    "            if re_search:\n",
    "                temp=re_search.group()\n",
    "                temp=re.split('\\.|,|:|\\(|\\)', temp)[0]\n",
    "                temp=temp.strip()\n",
    "                certificados_match_metric.append(temp)\n",
    "    #print('certificados_match_metric: ', certificados_match_metric)\n",
    "    certificados_match_metric = list(set(certificados_match_metric))\n",
    "    \n",
    "    certificados_match_segpres_string = \"\\n\".join([word for word in certificados_match_segpres])\n",
    "    certificados_match_metric_string = \"\\n\".join([word for word in certificados_match_metric])\n",
    "    \n",
    "    row = {'id_tramite': name,\n",
    "            'nombre_tramite': group['nombre_tramite'].values[0],\n",
    "            'certificados_segpres': certificados_match_segpres_string,\n",
    "            'certificados_metric': certificados_match_metric_string}\n",
    "\n",
    "    data_tramites_certificados_list.append(row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tramites_certificados_df = pd.DataFrame(data_tramites_certificados_list, columns=['id_tramite','nombre_tramite','certificados_segpres','certificados_metric'])\n",
    "data_tramites_certificados_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_tramites_certificados_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file='results/catastro_tramites - certificados_segpres_AND_metric.xlsx'\n",
    "\n",
    "writer = pd.ExcelWriter(output_file, engine='xlsxwriter')\n",
    "data_tramites_certificados_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "format1 = workbook.add_format({'text_wrap': True})\n",
    "\n",
    "worksheet.set_column('A:A', 10)\n",
    "worksheet.set_column('B:D', 50, format1)\n",
    "\n",
    "end_row = len(data_tramites_certificados_df.index)\n",
    "end_column = len(data_tramites_certificados_df.columns)-1\n",
    "header = [{'header': word} for word in data_tramites_certificados_df.columns.tolist()]\n",
    "\n",
    "worksheet.add_table(0, 0, end_row, end_column, {'header_row': True, 'columns': header})\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de DataFrame usando lista de certificados identificados por Metric y separados en múltiples registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_expand_certificados_group = data_expand_certificados_df.groupby('id_tramite')\n",
    "n_group = len(data_expand_certificados_group)\n",
    "\n",
    "data_tramites_certificados_list=[]\n",
    "for i, (name, group) in enumerate(data_expand_certificados_group):\n",
    "    requisitos_expand_list = list(group['requisitos_expand'])\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"Processing {} of {} - ID tramite: {}\".format(i, n_group, name))\n",
    "    \n",
    "    certificados_match_segpres = []\n",
    "    for requisito in requisitos_expand_list:\n",
    "        #print(requisito)\n",
    "        fuzz_match = process.extract(requisito, segpres_certificados_list, limit=2, scorer=fuzz.partial_ratio)\n",
    "        #print(fuzz_match)\n",
    "        for word in fuzz_match:\n",
    "            if word[1]>90:\n",
    "                certificados_match_segpres.append(word[0])\n",
    "    certificados_match_segpres = list(set(certificados_match_segpres))\n",
    "    \n",
    "    #print('requisitos_expand_list: ', requisitos_expand_list)\n",
    "    certificados_match_metric = []\n",
    "    for requisito in requisitos_expand_list:\n",
    "        #re_match = re.search('certificado\\S?\\s+\\w+\\s+\\w+', requisito)\n",
    "        re_match = re.findall('certificado.*?(?=certificado|$)', requisito)\n",
    "        for word in re_match:\n",
    "            # We match a phrase starting with the word certificado and add a maximum of 8 words\n",
    "            re_search=re.search('certificado(s)?(?:\\W+\\w+){,8}', word)\n",
    "            if re_search:\n",
    "                temp=re_search.group()\n",
    "                temp=re.split('\\.|,|:|\\(|\\)', temp)[0]\n",
    "                temp=temp.strip()\n",
    "                certificados_match_metric.append(temp)\n",
    "    #print('certificados_match_metric: ', certificados_match_metric)\n",
    "    certificados_match_metric = list(set(certificados_match_metric))\n",
    "    \n",
    "    for row in certificados_match_metric:\n",
    "        row = {'id_tramite': name,\n",
    "                'nombre_tramite': group['nombre_tramite'].values[0],\n",
    "                'certificados': row}\n",
    "\n",
    "        data_tramites_certificados_list.append(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tramites_certificados_df = pd.DataFrame(data_tramites_certificados_list, columns=['id_tramite','nombre_tramite','certificados'])\n",
    "data_tramites_certificados_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_tramites_certificados_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file='results/catastro_tramites - certificados_separados.xlsx'\n",
    "\n",
    "writer = pd.ExcelWriter(output_file, engine='xlsxwriter')\n",
    "data_tramites_certificados_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "format1 = workbook.add_format({'text_wrap': True})\n",
    "\n",
    "worksheet.set_column('A:A', 10)\n",
    "worksheet.set_column('B:D', 50, format1)\n",
    "\n",
    "end_row = len(data_tramites_certificados_df.index)\n",
    "end_column = len(data_tramites_certificados_df.columns)-1\n",
    "header = [{'header': word} for word in data_tramites_certificados_df.columns.tolist()]\n",
    "\n",
    "worksheet.add_table(0, 0, end_row, end_column, {'header_row': True, 'columns': header})\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
